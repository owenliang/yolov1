{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import VOCDetection\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image,ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE=448\n",
    "S=7\n",
    "C=20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VOC数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_ds=VOCDetection(root='./data',year='2012',image_set='train',download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img,label=voc_ds[4]\n",
    "print(label)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画框工具\n",
    "draw=ImageDraw.Draw(img)\n",
    "\n",
    "# 遍历每个object\n",
    "for obj in label['annotation']['object']:\n",
    "    box=obj['bndbox']\n",
    "    draw.rectangle([int(box['xmin']),int(box['ymin']),int(box['xmax']),int(box['ymax'])],\n",
    "                   outline='red',\n",
    "                   width=3)\n",
    "    draw.text([int(box['xmin'])+5,int(box['ymin'])+5],obj['name'],fill='red')\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img,label=voc_ds[4]\n",
    "\n",
    "scaled_img=img.resize((IMG_SIZE,IMG_SIZE)) # 缩放至YoloV1的尺寸\n",
    "\n",
    "# 缩放比\n",
    "x_scale=IMG_SIZE/img.width\n",
    "y_scale=IMG_SIZE/img.height\n",
    "\n",
    "draw=ImageDraw.Draw(scaled_img)\n",
    "for obj in label['annotation']['object']:\n",
    "    box=obj['bndbox']\n",
    "    draw.rectangle([int(box['xmin'])*x_scale,int(box['ymin'])*y_scale,int(box['xmax'])*x_scale,int(box['ymax'])*y_scale],\n",
    "                   outline='red',\n",
    "                   width=3)\n",
    "    draw.text([int(box['xmin'])*x_scale+5,int(box['ymin'])*y_scale+5],obj['name'],fill='red')\n",
    "\n",
    "scaled_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入dataset基类\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloVOCDataset(Dataset):\n",
    "    def __init__(self,voc_ds):\n",
    "        super().__init__()\n",
    "        self.voc_ds=voc_ds\n",
    "        \n",
    "        classdict=set()\n",
    "        for _,label in self.voc_ds:\n",
    "            for obj in label['annotation']['object']:\n",
    "                classdict.add(obj['name'])\n",
    "        self.id2name={i:c for i,c in enumerate(classdict)}\n",
    "        self.name2id={c:i for i,c in self.id2name.items()}\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        img,label=self.voc_ds[index]\n",
    "        \n",
    "        scaled_img=img.resize((IMG_SIZE,IMG_SIZE)) \n",
    "    \n",
    "        x_scale=IMG_SIZE/img.width\n",
    "        y_scale=IMG_SIZE/img.height\n",
    "        grid_size=IMG_SIZE//S\n",
    "        \n",
    "        x=ToTensor()(scaled_img)\n",
    "        y=torch.zeros(S,S,10+C)\n",
    "        \n",
    "        for obj in label['annotation']['object']:\n",
    "            box=obj['bndbox']\n",
    "            classid=self.name2id[obj['name']]\n",
    "            \n",
    "            # normal coordinates\n",
    "            xmin,ymin,xmax,ymax=int(box['xmin'])*x_scale,int(box['ymin'])*y_scale,int(box['xmax'])*x_scale,int(box['ymax'])*y_scale\n",
    "            xcenter,ycenter=(xmin+xmax)/2,(ymin+ymax)/2\n",
    "            width,height=xmax-xmin,ymax-ymin\n",
    "            grid_i,grid_j=int(xcenter//grid_size),int(ycenter//grid_size)\n",
    "            \n",
    "            # yolo coordinates\n",
    "            xcenter,ycenter=xcenter%grid_size/grid_size,ycenter%grid_size/grid_size\n",
    "            width,height=width/IMG_SIZE,height/IMG_SIZE\n",
    "            \n",
    "            # targets\n",
    "            y[grid_i,grid_j,0:5]=y[grid_i,grid_j,5:10]=torch.tensor([xcenter,ycenter,width,height,1])   # x,y,w,h,c\n",
    "            y[grid_i,grid_j,10:]=torch.zeros(20)\n",
    "            y[grid_i,grid_j,10+classid]=1\n",
    "        return x,y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.voc_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=YoloVOCDataset(voc_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=ds[0]\n",
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YoloV1 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn \n",
    "import torch\n",
    "\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloV1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.seq=nn.Sequential(\n",
    "            # 448*448\n",
    "            nn.Conv2d(in_channels=3,out_channels=64,kernel_size=7,stride=2,padding=3), \n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            \n",
    "            # 112*112\n",
    "            nn.Conv2d(in_channels=64,out_channels=192,kernel_size=3,stride=1,padding=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            \n",
    "            # 56*56\n",
    "            nn.Conv2d(in_channels=192,out_channels=128,kernel_size=1,stride=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(in_channels=128,out_channels=256,kernel_size=3,stride=1,padding=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(in_channels=256,out_channels=256,kernel_size=1,stride=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(in_channels=256,out_channels=512,kernel_size=3,stride=1,padding=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            \n",
    "            # 28*28\n",
    "            *[\n",
    "                nn.Conv2d(in_channels=512,out_channels=256,kernel_size=1,stride=1),\n",
    "                nn.LeakyReLU(0.1),\n",
    "                nn.Conv2d(in_channels=256,out_channels=512,kernel_size=3,stride=1,padding=1),\n",
    "                nn.LeakyReLU(0.1),\n",
    "            ]*4,\n",
    "            nn.Conv2d(in_channels=512,out_channels=512,kernel_size=1,stride=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(in_channels=512,out_channels=1024,kernel_size=3,stride=1,padding=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            \n",
    "            # 14*14\n",
    "            *[\n",
    "                nn.Conv2d(in_channels=1024,out_channels=512,kernel_size=1,stride=1),\n",
    "                nn.LeakyReLU(0.1),\n",
    "                nn.Conv2d(in_channels=512,out_channels=1024,kernel_size=3,stride=1,padding=1),\n",
    "                nn.LeakyReLU(0.1),\n",
    "            ]*2,\n",
    "            nn.Conv2d(in_channels=1024,out_channels=1024,kernel_size=3,stride=1,padding=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(in_channels=1024,out_channels=1024,kernel_size=3,stride=2,padding=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            \n",
    "            # 7*7\n",
    "            nn.Conv2d(in_channels=1024,out_channels=1024,kernel_size=3,stride=1,padding=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(in_channels=1024,out_channels=1024,kernel_size=3,stride=1,padding=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=7*7*1024,out_features=4096),\n",
    "            nn.Dropout(),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(in_features=4096,out_features=S*S*(10+C)),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self,x): # x:(batch,3,448,448)\n",
    "        y=self.seq(x)\n",
    "        return torch.reshape(y,(-1,S,S,10+C)) # (batch,7,7,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=YoloV1().to(device)\n",
    "x,y=ds[0]\n",
    "outputs=model(x.unsqueeze(0).to(device))\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(grid_row,grid_col,xywh_a,xywh_b):\n",
    "    grid_size=IMG_SIZE//S\n",
    "    \n",
    "    # yolo coordinates\n",
    "    xcenter_a,ycenter_a,w_a,h_a=xywh_a\n",
    "    xcenter_b,ycenter_b,w_b,h_b=xywh_b\n",
    "    \n",
    "    # normal coordinates\n",
    "    xcenter_a,ycenter_a=(grid_col+xcenter_a)*grid_size,(grid_row+ycenter_a)*grid_size\n",
    "    w_a,h_a=w_a*IMG_SIZE,h_a*IMG_SIZE\n",
    "    xcenter_b,ycenter_b=(grid_col+xcenter_b)*grid_size,(grid_row+ycenter_b)*grid_size\n",
    "    w_b,h_b=w_b*IMG_SIZE,h_b*IMG_SIZE\n",
    "    \n",
    "    # border\n",
    "    xmin_a,xmax_a,ymin_a,ymax_a=xcenter_a-w_a/2,xcenter_a+w_a/2,ycenter_a-h_a/2,ycenter_a+h_a/2\n",
    "    xmin_b,xmax_b,ymin_b,ymax_b=xcenter_b-w_b/2,xcenter_b+w_b/2,ycenter_b-h_b/2,ycenter_b+h_b/2\n",
    "    \n",
    "    # IOU\n",
    "    inter_xmin=max(xmin_a,xmin_b)\n",
    "    inter_xmax=min(xmax_a,xmax_b)\n",
    "    inter_ymin=max(ymin_a,ymin_b)\n",
    "    inter_ymax=min(ymax_a,ymax_b)\n",
    "    if inter_xmax<inter_xmin or inter_ymax<inter_ymin:\n",
    "        return 0\n",
    "\n",
    "    inter_area=(inter_xmax-inter_xmin)*(inter_ymax-inter_ymin) # 交集\n",
    "    union_area=w_a*h_a+w_b*h_b-inter_area # 并集\n",
    "    return inter_area/union_area # IOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_coord=5\n",
    "lambda_noojb=0.5\n",
    "\n",
    "model=YoloV1().to(device)\n",
    "dataloader=DataLoader(ds,batch_size=32,shuffle=True)\n",
    "optimizer=optim.Adam(model.parameters(),lr=1e-4)\n",
    "\n",
    "for epoch in range(50):\n",
    "    for batch_x,batch_y in dataloader:\n",
    "        batch_x,batch_y=batch_x.to(device),batch_y.to(device)\n",
    "        batch_output=model(batch_x)\n",
    "        \n",
    "        loss=torch.tensor(0)\n",
    "        for i in range(len(batch_x)):\n",
    "            x=batch_x[i]\n",
    "            y=batch_y[i]\n",
    "            output=batch_output[i]\n",
    "            # foreach grid \n",
    "            for row in range(S):    \n",
    "                for col in range(S):\n",
    "                    pred_grid=output[row,col] \n",
    "                    target_grid=y[row,col]\n",
    "                    if not target_grid[4]>0: # no object in this grid\n",
    "                        loss_c_noobj=(pred_grid[4])**2+(pred_grid[9])**2 # no object in grid,so target c is 0\n",
    "                        loss=loss+lambda_noojb*loss_c_noobj\n",
    "                        continue \n",
    "                    # IOU\n",
    "                    iou_bbox1=compute_iou(row,col,pred_grid[:4],target_grid[:4])\n",
    "                    iou_bbox2=compute_iou(row,col,pred_grid[5:9],target_grid[:4])\n",
    "                    # 取IOU大的预测框的x,y,w,h,c\n",
    "                    if iou_bbox1>iou_bbox2:\n",
    "                        xywh=pred_grid[:4]\n",
    "                        c_obj,c_noobj=pred_grid[4],pred_grid[9]\n",
    "                    else:\n",
    "                        xywh=pred_grid[5:9]\n",
    "                        c_obj,c_noobj=pred_grid[9],pred_grid[4]\n",
    "                    loss_xywh=(xywh[0]-target_grid[0])**2+(xywh[1]-target_grid[1])**2+(torch.sqrt(xywh[2])-torch.sqrt(target_grid[2]))**2+(torch.sqrt(xywh[3])-torch.sqrt(target_grid[3]))**2\n",
    "                    loss_c_obj=(c_obj-1)**2\n",
    "                    loss_c_noobj=(c_noobj)**2\n",
    "                    loss_class=((pred_grid[10:]-target_grid[10:])**2).sum()\n",
    "                    loss=loss+loss_xywh*lambda_coord+loss_c_obj+loss_c_noobj*lambda_noojb+loss_class\n",
    "        loss=loss/len(batch_x)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
